{
  "dataset_reader": {
    "type": "nq",
    "tokenizer": {
      "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad"
    },
    "token_indexers": {
      "tokens": {
        "type": "pretrained_transformer",
        "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad"
      }
    },
    "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad",
    "is_training": true,
    "lazy": true,
    "cache_directory": "cache_train"
  },
  "validation_dataset_reader": {
    "type": "nq",
    "tokenizer": {
      "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad"
    },
    "token_indexers": {
      "tokens": {
        "type": "pretrained_transformer",
        "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad"
      }
    },
    "model_name": "bert-large-uncased-whole-word-masking-finetuned-squad",
    "is_training": false,
    "lazy": true,
    "cache_directory": "cache_val"
  },
  "data_loader": {
    "batch_size": 3
  },
  "model": {
    "type": "nq",
    "bert_pretrained_model": "bert-large-uncased-whole-word-masking-finetuned-squad"
  },
  "vocabulary": {
    "type": "from_files",
    "directory": "bert_large_samples_output/vocabulary/"
  },
  "train_data_path": "data/nq/output/nq-train-0.0.1.json",
  "validation_data_path": "data/nq/output/nq-val-0.0.1.json",
  "trainer": {
    "cuda_device": 0,
    "num_epochs": 4,
    "optimizer": {
      "type": "adam",
      "lr": 1e-05
    },
    "opt_level": "O2",
    "num_gradient_accumulation_steps": 10
  }
}